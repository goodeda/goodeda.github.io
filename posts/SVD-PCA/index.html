<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="PCA &amp; SVD" /><meta property="og:locale" content="en" /><meta name="description" content="PCA details In machine learning, threre are many features can be used for training. For example, we have 72 features in each instance and 1000 pieces of data. So now we have a matrix D with shape of (1000, 72). If we want to reduce the feature number, then we need another matrix R and compute dot product: $D * R = D^{‘}$ Suppose the shape of R is (72, 30), and the $D^{‘}$ is in (1000, 30). So the now our task is to find a good $R$ to keep as much information as possible." /><meta property="og:description" content="PCA details In machine learning, threre are many features can be used for training. For example, we have 72 features in each instance and 1000 pieces of data. So now we have a matrix D with shape of (1000, 72). If we want to reduce the feature number, then we need another matrix R and compute dot product: $D * R = D^{‘}$ Suppose the shape of R is (72, 30), and the $D^{‘}$ is in (1000, 30). So the now our task is to find a good $R$ to keep as much information as possible." /><link rel="canonical" href="https://goodeda.github.io/posts/SVD-PCA/" /><meta property="og:url" content="https://goodeda.github.io/posts/SVD-PCA/" /><meta property="og:site_name" content="Zhixu" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-05-27T22:55:00+03:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="PCA &amp; SVD" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-09-22T15:05:21+03:00","datePublished":"2022-05-27T22:55:00+03:00","description":"PCA details In machine learning, threre are many features can be used for training. For example, we have 72 features in each instance and 1000 pieces of data. So now we have a matrix D with shape of (1000, 72). If we want to reduce the feature number, then we need another matrix R and compute dot product: $D * R = D^{‘}$ Suppose the shape of R is (72, 30), and the $D^{‘}$ is in (1000, 30). So the now our task is to find a good $R$ to keep as much information as possible.","headline":"PCA &amp; SVD","mainEntityOfPage":{"@type":"WebPage","@id":"https://goodeda.github.io/posts/SVD-PCA/"},"url":"https://goodeda.github.io/posts/SVD-PCA/"}</script><title>PCA & SVD | Zhixu</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Zhixu"><meta name="application-name" content="Zhixu"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src=" /assets/img/favicon/android-chrome-512x512.png " alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Zhixu</a></div><div class="site-subtitle font-italic">NLP, mathematics and languages.</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/projects/" class="nav-link"> <i class="fa-fw fa fa-cubes ml-xl-3 mr-xl-3 unloaded"></i> <span>PROJECTS</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-user-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/goodeda" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['guzhixu','outlook.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>PCA & SVD</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>PCA & SVD</h1><div class="post-meta text-muted"><div> By <em> <a href="https://github.com/username">zhixu</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" data-ts="1653681300" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2022-05-27 </em> </span> <span> Updated <em class="timeago" data-ts="1663848321" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2022-09-22 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1359 words"> <em>7 min</em> read</span></div></div></div><div class="post-content"><h2 id="pca-details"><span class="mr-2">PCA details</span><a href="#pca-details" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>In machine learning, threre are many features can be used for training. For example, we have 72 features in each instance and 1000 pieces of data. So now we have a matrix <strong>D</strong> with shape of (1000, 72). If we want to reduce the feature number, then we need another matrix <strong>R</strong> and compute dot product: $D * R = D^{‘}$ Suppose the shape of R is (72, 30), and the $D^{‘}$ is in (1000, 30). So the now our task is to find a good $R$ to keep as much information as possible.</p><h3 id="maximum-variance"><span class="mr-2">Maximum variance</span><a href="#maximum-variance" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p><img data-src="https://raw.githubusercontent.com/goodeda/goodeda.github.io/main/assets/post_img/PCA-max_var.PNG" alt="" data-proofer-ignore><br /> Pic from <a href="https://mml-book.github.io/">Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong, 2020</a><br /> We can see if wee want to reduce dimension form 2 to 1, the best line is what is shown in the picture. This is understandable because the projections of dots are more discrete. Let’s consider an opposite case, say the line is perpendicular to the original one. Then the projects lie on a very narrow area, for example, they are [1, 0] [1.5, 0], [1, 0] [-1, 0] [1, 0] [-0.5, 0], which are ineffective to represent original points because a lot of them look exactly the same.<br /> Therefore, we wish the projection has the max variance so that most information is kept.</p><h3 id="covariance"><span class="mr-2">Covariance</span><a href="#covariance" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>Based on above discussion, we should be able to know the task is to find a plane where the variance is max. Variance formula is as follows</p>\[\begin{equation} S = \frac{1}{N-1} \Sigma_{i}^{N} (x_{i}-\bar{x})^{2} \end{equation}\]<p>Where N is the number of dimensions.<br /> If we change the equation a little bit, then it turns to $Cov(x,y)=\frac{1}{N-1} \Sigma_{i}^{N} (x_{i}-\bar{x})*(y_{i}-\bar{x})$ which is a covairance matrix. When x = y the value is actually the variance of x.</p><p>Before we do the projection, we must first standardize the data, then do the projection and maximize the variance.</p>\[\begin{equation} \begin{aligned} J &amp;= \frac{1}{N-1}\Sigma_{i=1}^{N} ((x_{i}-\bar{x})\mu)^{2}\\ &amp;= \frac{1}{N-1}\Sigma_{i=1}^{N} \mu^{T}(x_{i}-\bar{x})^{T}(x_{i}-\bar{x})\mu \\ &amp;= \mu^{T} \frac{1}{N-1}\Sigma_{i=1}^{N} (x_{i}-\bar{x})^{T}(x_{i}-\bar{x})\mu \\ &amp;= \mu^{T}S\mu \end{aligned} \end{equation}\]<p>Where $\mu$ is the $R$ we mentioned in previous section. There is another property for $\mu$: $\mu^{T}\mu = 1$ which results from the fact that covariance matrix is always a systematric square.</p><p>Then the whole question becomes an optimization problem. To find the best $\mu$ so that the $J$ is maximum variance.</p>\[argmax (J) = \mu^{T}S\mu\] \[s.t. \: \mu^{T}\mu = 1\]<p>Use Lagrange multiplier to solve the problem.</p>\[L(\mu, \lambda) = \mu^{T}S\mu +\lambda(1-\mu^{T}\mu) \\\]<p>The equation is max when the following requirement(just one of them, but enough) is met.</p>\[\frac{\partial L}{\partial \mu} = 2S\mu - 2\lambda \mu =0\]<p>The result is $S\mu = \lambda \mu$ which indicates $\lambda$ stands for eigenvalues of $S$, and $\mu$ for eigenvectors.<br /> By computing eigenvectors corresponding to top X largest eigenvalues, we obtain the $\mu$ to reduce dimensions.</p><h3 id="eigenvalue--eigenvector"><span class="mr-2">Eigenvalue &amp; Eigenvector</span><a href="#eigenvalue--eigenvector" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>Definition: $A x = \lambda x$ =&gt; $|A - \lambda E|=0$<br /> The $\lambda$ holds the equation is eigenvalue and the $x$ is eigenvector.</p><ul><li>$A$ should be a square matrix.<li>If $A(n,n)$ is not invertible ($A$ is singular, rank is less than n), there must be at least one $\lambda$ is <strong>zero</strong>.</ul><p>For example, now square matrix</p>\[A=\left[ \begin{matrix} 12 &amp; 8 \\ 5 &amp; 6 \\ \end{matrix} \right]\] \[\begin{aligned} |A - \lambda I| &amp;= det \left\{ \left[ \begin{matrix} 12-\lambda &amp; 8 \\ 5 &amp; 6-\lambda \\ \end{matrix} \right] \right\} \\ &amp;=(12-\lambda)(6-\lambda)-5*8 \\ &amp;= \lambda^{2} - 18\lambda + 72 - 40 \\ &amp;= \lambda^{2} - 18\lambda + 32 \\ &amp;= (\lambda -16)(\lambda -2)\\ \end{aligned} \\\]<p>So the $\lambda_{1}=2, \lambda_{2}=16$ and the $x_{1}=\begin{bmatrix} -4 \ 5 \end{bmatrix}$ and $x_{2}=\begin{bmatrix} 2 \ 1 \end{bmatrix}$</p><p>But here is a restriction that the matrix has to be a N x N matrix. However, in reality there are many matrices in shape of N x M.</p><h2 id="svd"><span class="mr-2">SVD</span><a href="#svd" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="singular-value-and-vector"><span class="mr-2">Singular value and vector</span><a href="#singular-value-and-vector" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>Consequently, singular values and vectors are designed for those matrices whose rows(N) are different from columns(M).<br /> Suppose we can decompose $A=U\Sigma V^{T}$, where $U$ and $V$ are both <strong>orthogonal</strong>. Then the followings also hold</p><ol><li>$AA^{T}=U\Sigma V^{T}(U\Sigma V^{T})^{T}=U\Sigma V^{T}V\Sigma U^{T}=U\Sigma \Sigma U^{T}$<li>$A^{T}A=(U\Sigma V^{T})^{T}U\Sigma V^{T}=V\Sigma U^{T}U\Sigma V^{T}=V\Sigma \Sigma V^{T}$</ol><p>So the singular values are the root square of $\Sigma$ values. For example,</p><p>\(A=\left[ \begin{smallmatrix} 3 &amp; 2 \\ 2 &amp; 3 \\ 2 &amp; -2 \\ \end{smallmatrix} \right]\)<br /> and \(A^{T}=\left[ \begin{smallmatrix} 3 &amp; 2 &amp; 2 \\ 2 &amp; 3 &amp; -2 \\ \end{smallmatrix} \right]\)</p><p>We first calculate the $V$</p>\[\begin{aligned} A^{T}A &amp;=\left[ \begin{matrix} 3 &amp; 2 &amp; 2 \\ 2 &amp; 3 &amp; -2 \\ \end {matrix}\right]*\left[ \begin{matrix} 3 &amp; 2 \\2 &amp; 3 \\ 2 &amp; -2 \\\end{matrix}\right] \\ &amp;= \left[ \begin{matrix} 17 &amp; 8 \\ 8 &amp; 17 \\\end {matrix}\right] \end{aligned}\]<p>$det(A^{T}A)=\lambda^{2}-34\lambda+289-64=(\lambda -9)(\lambda-25)$ so the singular value $q_{1}=\sqrt 9 = 3$ and $q_{2}=\sqrt 25 = 5$ and we rank the singular values:<br /> \(v_{1}=\frac{1}{\sqrt 2} \begin{bmatrix} 1 \\ -1 \\ \end{bmatrix}, v_{2}=\frac{1}{\sqrt 2} \begin{bmatrix} 1 \\ 1 \\ \end{bmatrix} , V=\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \\ \end{bmatrix}, \Sigma= \begin{bmatrix} 5 &amp; 0 \\ 0 &amp; 3 \\ \end{bmatrix}\)</p><p>According to $U=AV\Sigma^{-1},\; u_{i}=\frac{Av_{i}}{\sigma_{i}}$, we know:</p>\[\begin{aligned} u_{1}&amp;=\frac{\left[ \begin{matrix} 3 &amp; 2 \\2 &amp; 3 \\ 2 &amp; -2 \\\end{matrix}\right]*\frac{1}{\sqrt 2}\left[ \begin{matrix} 1 \\ 1 \\\end {matrix}\right]}{5} &amp;=\frac{1}{\sqrt 2}\left[ \begin{matrix} 1 \\ 1 \\ 0 \end {matrix}\right] \\ u_{2}&amp;=\frac{\left[ \begin{matrix} 3 &amp; 2 \\2 &amp; 3 \\ 2 &amp; -2 \\\end{matrix}\right]*\frac{1}{\sqrt 2}\left[ \begin{matrix} 1 \\ -1 \\\end {matrix}\right]}{3} &amp;= \frac{1}{\sqrt 2} \left[ \begin{matrix} 1/3 \\ -1/3 \\ 4/3 \end {matrix}\right] \end{aligned}\]<p>And the</p>\[U=\frac{1}{\sqrt 2}\begin{bmatrix} 1 &amp; 1/3 \\ 1 &amp; -1/3 \\ 0 &amp; 4/3 \\ \end{bmatrix}\]<p>And now we can verify:</p>\[U\Sigma V^{T}=\frac{1}{\sqrt 2}\begin{bmatrix} 1 &amp; 1/3 \\ 1 &amp; -1/3 \\ 0 &amp; 4/3 \\ \end {bmatrix}* \begin{bmatrix} 5 &amp; 0 \\ 0 &amp; 3 \\ \end{bmatrix} * \frac{1}{\sqrt 2} \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \\ \end{bmatrix} =\frac{1}{2} \begin{bmatrix} 6 &amp; 4 \\ 4 &amp; 6 \\ 4 &amp; -4 \\ \end{bmatrix}=A\]<h3 id="application"><span class="mr-2">Application</span><a href="#application" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>So in which way can it be used? The general form of SVD is:</p><p>\(\begin{bmatrix} a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1m} \\ a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2m} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nm}\\\end {bmatrix}_{(n \times m)} = \left[ \begin{matrix} u_{11} &amp; \cdots &amp; u_{1k} \\ \vdots &amp; \ddots &amp; \vdots\\ u_{n1} &amp; \cdots &amp; u_{nk}\\\end {matrix}\right]_{(n \times k)} \left[ \begin{matrix} \sigma_{1} &amp; 0 &amp; \cdots &amp; 0 &amp; 0 \\ 0 &amp; \sigma_{2} &amp; \cdots &amp; 0 &amp; 0\\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \\ 0 &amp; 0 &amp; \cdots &amp; \sigma_{k-1} &amp; 0 \\ 0 &amp; 0 &amp; \cdots &amp; 0 &amp; \sigma_{k}\\\end {matrix}\right]_{(k \times k)} \left[ \begin{matrix} v_{11} &amp; \cdots &amp; v_{1k} \\ \vdots &amp; \ddots &amp; \vdots\\ v_{m1} &amp; \cdots &amp; v_{mk}\\\end {matrix}\right]^{T}_{(k \times m)}\) where $\sigma_{i}$ is ranked by value from high to low, which indicates the contribution of $\sigma_{i}$.<br /> Sometimes the last several values like $\sigma_{k}$ are quite small/close to 0, and they can be just removed. And the form is:</p>\[U^{'}_{(n \times j)}\Sigma^{'}_{(j \times j)} V^{'T}_{(j \times m)}\]<p>This way of decomposition saves the most information of matrix.</p><h4 id="python-code"><span class="mr-2">Python code</span><a href="#python-code" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4></h4><p>By running the following code, it shows the original picture</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">tower</span><span class="o">=</span><span class="n">Image</span><span class="p">.</span><span class="nb">open</span><span class="p">(</span><span class="s">"SVD-origin.jpg"</span><span class="p">,</span><span class="s">"r"</span><span class="p">)</span><span class="c1"># file name could be replaced
</span><span class="n">tower_pixel_matrix</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">tower</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">tower</span><span class="p">)</span>
</pre></table></code></div></div><div align="center"><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 300 400'%3E%3C/svg%3E" data-src="https://github.com/goodeda/goodeda.github.io/raw/main/assets/post_img/SVD-origin.jpg" width="300" height="400" alt="Rheinturm" data-proofer-ignore></div><center>Rhine Tower, Dusseldorf (So beautiful!)</center><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">z</span><span class="o">=</span><span class="n">tower_pixel_matrix</span><span class="p">.</span><span class="n">shape</span>
<span class="n">tower_pixel_matrix</span> <span class="o">=</span> <span class="n">tower_pixel_matrix</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="o">*</span><span class="n">z</span><span class="p">)</span>
<span class="n">U</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">V</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">svd</span><span class="p">(</span><span class="n">tower_pixel_matrix</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">),(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">100</span><span class="p">),(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">500</span><span class="p">)]:</span>
    <span class="n">blurred_tower</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="n">k</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">diag</span><span class="p">(</span><span class="n">sigma</span><span class="p">[:</span><span class="n">k</span><span class="p">[</span><span class="mi">2</span><span class="p">]])</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">V</span><span class="p">[:</span><span class="n">k</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="p">:])</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">]].</span><span class="n">imshow</span><span class="p">(</span><span class="n">blurred_tower</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">k</span><span class="p">[</span><span class="mi">1</span><span class="p">]].</span><span class="n">title</span><span class="p">.</span><span class="n">set_text</span><span class="p">(</span><span class="s">"Key components:{}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">k</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
</pre></table></code></div></div><div align="center"><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1000 600'%3E%3C/svg%3E" data-src="https://raw.githubusercontent.com/goodeda/goodeda.github.io/main/assets/post_img/SVD-blurred.jpg" width="1000" height="600" alt="Rheinturm" data-proofer-ignore></div><center>Picture compression</center><p>It’s clear that key components save the most important information, like the outline of objects. The more components are saved, the more details are provided.</p><p><code class="language-plaintext highlighter-rouge">sklearn</code> provides API for <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html">SVD</a> as well. This approach is usually applied to reduce dimensions of data at the least cost. It’s a very useful method in machine learning. This method can also be used in NLP field. For example, Latent Semantic Analysis(LSA) uses SVD to map the term-document on certain space and grouping words of similar semantic meaning.</p><h3 id="reference"><span class="mr-2">Reference</span><a href="#reference" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><ul><li><a href="https://math.mit.edu/~gs/learningfromdata/">Linear Algebra and Learning from Data (2019)</a><li><a href="https://www.frankcleary.com/svdimage/">Image compression idea</a><li><a href="https://mml-book.github.io/">Mathematics for machine learning</a></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/english/'>English</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/math/" class="post-tag no-text-decoration" >math</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=PCA &amp; SVD - Zhixu&amp;url=https://goodeda.github.io/posts/SVD-PCA/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=PCA &amp; SVD - Zhixu&amp;u=https://goodeda.github.io/posts/SVD-PCA/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https://goodeda.github.io/posts/SVD-PCA/&amp;text=PCA &amp; SVD - Zhixu" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/SVD-PCA/">PCA & SVD</a><li><a href="/posts/app-visual/">App analysis with review information on google play</a><li><a href="/posts/Power-BI-Practice/">Power BI practice for data visualization</a><li><a href="/posts/Logistic-Regression/">Logistic Regression</a><li><a href="/posts/bisystem/">Virtual machine on Windows</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/p%C3%A4iv%C3%A4kirja/">päiväkirja</a> <a class="post-tag" href="/tags/math/">math</a> <a class="post-tag" href="/tags/projects/">Projects</a> <a class="post-tag" href="/tags/data-structure-algorithm/">data-structure-algorithm</a> <a class="post-tag" href="/tags/language-learning/">Language-learning</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/power-bi/">POWER-BI</a> <a class="post-tag" href="/tags/visualization/">Visualization,</a> <a class="post-tag" href="/tags/word-segmentation/">word-segmentation</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/testing-mathjax/"><div class="card-body"> <em class="timeago small" data-ts="1588334400" > 2020-05-01 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Poisson Process</h3><div class="text-muted small"><p> Poisson Process 泊松过程主要刻画小概率事件在一段时间内发生的情况，在排队论，等待时间，累计损耗计算方面有很大用处。 泊松过程的三种定义 有计数过程N(t),如果满足以下条件： \(\left\{ \begin{array}{llll} N(0)=0, 0\;\;time\; happens\; in\; 0\; time &amp;amp; \\ N(t)\; ...</p></div></div></a></div><div class="card"> <a href="/posts/Logistic-Regression/"><div class="card-body"> <em class="timeago small" data-ts="1662726180" > 2022-09-09 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Logistic Regression</h3><div class="text-muted small"><p> As I’m taking the Models and algorithms in NLP-application course, here I take notes of some classical machine learning models. In addition, I try to build the model without importing sklearn packa...</p></div></div></a></div><div class="card"> <a href="/posts/SSH-KEY/"><div class="card-body"> <em class="timeago small" data-ts="1661369400" > 2022-08-24 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Password-less for connecting Github and remote server</h3><div class="text-muted small"><p> I used to enter the password when pushing file to Github or connecting to remote server. I always feel this step redundant and recently came to konw that SSH is a good solution. I want to record th...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/unigram-word-segmentation/" class="btn btn-outline-primary" prompt="Older"><p>Chinese word segmentation statistical approach(I)</p></a> <a href="/posts/Hackathon22/" class="btn btn-outline-primary" prompt="Newer"><p>DHH22 Hackathon Project</p></a></div><script type="text/javascript"> $(function () { const origin = "https://giscus.app"; const iframe = "iframe.giscus-frame"; const lightTheme = "light"; const darkTheme = "dark_dimmed"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } let giscusAttributes = { "src": "https://giscus.app/client.js", "data-repo": "goodeda/goodeda.github.io", "data-repo-id": "", "data-category": "", "data-category-id": "", "data-mapping": "pathname", "data-reactions-enabled": "1", "data-emit-metadata": "0", "data-theme": initTheme, "data-input-position": "bottom", "data-lang": "en", "crossorigin": "anonymous", "async": "" }; let giscusScript = document.createElement("script"); Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value)); document.getElementById("tail-wrapper").appendChild(giscusScript); addEventListener("message", (event) => { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); const message = { setConfig: { theme: theme } }; const giscus = document.querySelector(iframe).contentWindow; giscus.postMessage({ giscus: message }, origin); } }); }); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2022 <a href="https://github.com/username">zhixu</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/p%C3%A4iv%C3%A4kirja/">päiväkirja</a> <a class="post-tag" href="/tags/math/">math</a> <a class="post-tag" href="/tags/projects/">Projects</a> <a class="post-tag" href="/tags/data-structure-algorithm/">data-structure-algorithm</a> <a class="post-tag" href="/tags/language-learning/">Language-learning</a> <a class="post-tag" href="/tags/linux/">Linux</a> <a class="post-tag" href="/tags/nlp/">NLP</a> <a class="post-tag" href="/tags/power-bi/">POWER-BI</a> <a class="post-tag" href="/tags/visualization/">Visualization,</a> <a class="post-tag" href="/tags/word-segmentation/">word-segmentation</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
